[
  {
    "timestamp": "2025-08-31T18:51:22.628498",
    "algorithm": "PPO",
    "model_variant": "balanced",
    "timesteps": 100000,
    "eval_score": -521.04593564,
    "model_path": "multi_model_training_20250831_172815/models/ppo/ppo_balanced_20250831_185122_step100000",
    "recent_rewards": [
      -518.619426,
      40.180647,
      297.480113,
      57.189708,
      45.981455,
      -899.652829,
      99.066211,
      -1037.739507,
      -23.730939,
      46.681815,
      -8.479665,
      41.288308,
      29.478026,
      -20.112689,
      -176.805966,
      -109.048113,
      79.670269,
      13.670703,
      -720.952264,
      100.494187
    ]
  },
  {
    "timestamp": "2025-08-31T18:53:51.972717",
    "algorithm": "PPO",
    "model_variant": "balanced",
    "timesteps": 200000,
    "eval_score": -220.63464946,
    "model_path": "multi_model_training_20250831_172815/models/ppo/ppo_balanced_20250831_185351_step200000",
    "recent_rewards": [
      50.852213,
      -90.966702,
      100.272814,
      75.123611,
      -570.617804,
      280.049208,
      151.217382,
      107.053492,
      -1000.662422,
      185.786526,
      448.859597,
      -136.522659,
      45.995787,
      -101.29769,
      -89.856774,
      -45.493254,
      56.273096,
      -181.016901,
      -145.4152,
      150.480538
    ]
  },
  {
    "timestamp": "2025-08-31T18:58:57.685940",
    "algorithm": "PPO",
    "model_variant": "balanced",
    "timesteps": 400000,
    "eval_score": 266.34462994,
    "model_path": "multi_model_training_20250831_172815/models/ppo/ppo_balanced_20250831_185857_step400000",
    "recent_rewards": [
      75.35733,
      -241.719345,
      -226.368406,
      -96.989886,
      -699.707429,
      -184.661329,
      -1291.58114,
      -31.641297,
      30.574453,
      -18.546993,
      377.513811,
      -651.979733,
      -172.320017,
      384.019951,
      57.582288,
      162.573949,
      -681.331291,
      -345.946242,
      -719.21845,
      5.514734
    ]
  },
  {
    "timestamp": "2025-08-31T19:01:25.886350",
    "algorithm": "PPO",
    "model_variant": "balanced",
    "timesteps": 500000,
    "eval_score": 401.00926253999995,
    "model_path": "multi_model_training_20250831_172815/models/ppo/ppo_balanced_20250831_190125_step500000",
    "recent_rewards": [
      541.137814,
      -29.132277,
      -875.517165,
      33.359466,
      -14.024179,
      -1023.525153,
      -1156.485833,
      26.987703,
      540.528307,
      201.591818,
      32.86437,
      -1013.786641,
      1.197353,
      165.462394,
      53.235622,
      -145.83107,
      19.751375,
      277.874621,
      -140.253474,
      73.091348
    ]
  }
]