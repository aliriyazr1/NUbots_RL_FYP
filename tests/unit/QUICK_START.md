# Quick Start Guide - Reward Function Tests

**Student:** Ali Riyaz (C3412624)

## TL;DR

```bash
# Run all tests
pytest tests/unit/test_reward_function.py -v -s

# All 13 tests should pass ‚úì
```

## What Was Tested

‚úì Reward bounds (no NaN/inf, reasonable range)
‚úì Goal scoring (+150 reward)
‚úì Anti-exploitation (stationary holding, wall hugging)
‚úì Component behaviour (possession, goal progress)
‚úì Reward smoothness (no discontinuities)

## Key Finding üîç

**The `goal_progress` component dominates the reward signal (~85%)**

This explains why the agent learns "technically correct but wrong" behaviours - it's optimising goal distance above all else.

**Fix:** Reduce `goal_weight` or `potential_scale` in `configs/field_config.yaml`

## Quick Commands

```bash
# Test specific issue
pytest tests/unit/test_reward_function.py::TestAntiExploitationMeasures::test_stationary_ball_holding_penalty -v -s

# See component breakdown
pytest tests/unit/test_reward_function.py::TestRewardScaling::test_reward_component_balance -v -s
```

## Files Created

- `test_reward_function.py` - Main test suite (592 lines)
- `README_TESTS.md` - Detailed documentation
- `TEST_RESULTS_SUMMARY.md` - Analysis and findings
- `QUICK_START.md` - This file

## Next Steps

1. Review `TEST_RESULTS_SUMMARY.md` for detailed findings
2. Tune reward weights based on component analysis
3. Strengthen anti-exploitation penalties
4. Re-run tests after changes

## For Thesis

Tests validate:
- Mathematical soundness (continuous, differentiable)
- Systematic testing methodology
- Quantitative reward analysis

See `TEST_RESULTS_SUMMARY.md` for academic documentation templates.