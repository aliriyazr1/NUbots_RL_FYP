[
  {
    "timestamp": "2025-08-31T19:30:32.367944",
    "algorithm": "PPO",
    "model_variant": "exploration",
    "timesteps": 100000,
    "eval_score": -378.71567109999995,
    "model_path": "multi_model_training_20250831_172815/models/ppo/ppo_exploration_20250831_193032_step100000",
    "recent_rewards": [
      25.237735,
      -752.639099,
      757.002415,
      -414.584848,
      184.405254,
      375.19824,
      131.21417,
      -769.269927,
      -373.756434,
      -610.165131,
      -653.88995,
      -219.11612,
      -215.343794,
      21.8736,
      -79.653818,
      -11.513397,
      312.141667,
      -7.269379,
      36.444328,
      106.881823
    ]
  },
  {
    "timestamp": "2025-08-31T19:32:57.036266",
    "algorithm": "PPO",
    "model_variant": "exploration",
    "timesteps": 200000,
    "eval_score": 638.55264626,
    "model_path": "multi_model_training_20250831_172815/models/ppo/ppo_exploration_20250831_193256_step200000",
    "recent_rewards": [
      -331.883538,
      -880.47656,
      6.088832,
      -4.558719,
      -488.454954,
      331.277679,
      355.794938,
      211.571244,
      -792.854076,
      -1076.918923,
      -929.78621,
      -399.351672,
      78.927962,
      -397.046794,
      52.202142,
      -64.321672,
      48.927922,
      -125.574606,
      -608.596725,
      202.125798
    ]
  },
  {
    "timestamp": "2025-08-31T19:40:09.471979",
    "algorithm": "PPO",
    "model_variant": "exploration",
    "timesteps": 500000,
    "eval_score": 961.86659704,
    "model_path": "multi_model_training_20250831_172815/models/ppo/ppo_exploration_20250831_194009_step500000",
    "recent_rewards": [
      -398.853159,
      -291.984053,
      -41.257955,
      -1.513092,
      288.826064,
      -27.926086,
      453.321003,
      -77.974478,
      31.560126,
      -221.518739,
      43.781784,
      66.216939,
      -55.329214,
      -234.366035,
      451.074687,
      63.088367,
      119.845235,
      97.788148,
      30.356333,
      191.72942
    ]
  },
  {
    "timestamp": "2025-08-31T19:45:13.854789",
    "algorithm": "PPO",
    "model_variant": "exploration",
    "timesteps": 700000,
    "eval_score": 1498.36763748,
    "model_path": "multi_model_training_20250831_172815/models/ppo/ppo_exploration_20250831_194513_step700000",
    "recent_rewards": [
      139.58663,
      860.373399,
      683.403848,
      -726.687872,
      -3.401174,
      -139.855769,
      513.400411,
      -10.671447,
      -58.750323,
      371.726178,
      -217.102707,
      -218.378504,
      570.93893,
      175.434648,
      19.469222,
      -280.035592,
      269.072865,
      212.814885,
      -95.934075,
      -973.366471
    ]
  }
]